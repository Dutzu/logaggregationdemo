####
## Source descriptions:
##

#secure input source from log shippers
<source>
	@type secure_forward
	shared_key "#{ENV['FLUENTD_SHARED_KEY']}"
	self_hostname fs-efk-aggregator

	ca_cert_path /fluentd/certs/ca_cert.pem
	ca_private_key_path /fluentd/certs/ca_key.pem
	ca_private_key_passphrase "#{ENV['FLUENTD_CERT_PASSPHRASE']}"

	secure true

	#for authentication
	authentication yes
	<user>
		username "#{ENV['FLUENTD_AGGREGATOR_USERNAME']}"
		password "#{ENV['FLUENTD_AGGREGATOR_PASSWORD']}"
	</user>
</source>

####
## Filter descriptions:
##


####
## Output descriptions:
##


<match fs.**>
	@type copy
	<store>
		@type stdout
	</store>
	<store>
    type elasticsearch
    logstash_format true
    host elasticsearch
		port 9200

		buffer_type file
    buffer_path /fluentd/buffer/log.*.buffer
    buffer_chunk_limit 8m
    buffer_queue_limit 128
    flush_interval 10s
    flush_at_shutdown true
    retry_wait 30s
    max_retry_wait 1h
    disable_retry_limit true
    keepalive 300
	</store>
</match>

<match fluent.**>
  # These logs will either go to td-agent.log if run stand-alone or will
	# be caught by the docker log driver and pushed to the internal logs if
	# used in a dockerized version.
	type stdout
</match>

# Re-tag and re-emit messages to match them to specific parsing rules based on the container name
# Syntax: rewriterule<num> <attribute> <regex_pattern> <new_tag>
# For basic filtering we use a contains regex pattern like: \/wildfly
<match **>
	@type rewrite_tag_filter
  #be careful, here the name of the container is weakly linked to the name of the docker-compose service
  #this is so that we can have strict control over what messages we try to parse with more exact rules.
	rewriterule1 sourceEnvironment dev myapps.dev
	rewriterule2 sourceEnvironment integration myapps.integration
	rewriterule3 sourceEnvironment live myapps.live
	rewriterule4 sourceEnvironment .* myapps.unknownenv
</match>